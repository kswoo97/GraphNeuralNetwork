{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solubility Regression\n",
    "\n",
    "### Yonsei App.Stat.\n",
    "### Sunwoo Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 분자구조의 융해성(solubility)을 회귀하는 문제입니다.  \n",
    "사용한 모델은 Message Passing Neural Network입니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pysmiles import read_smiles\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data related\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Model importing\n",
    "from solubility_gnn import *\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"solubility_original_data.csv\")\n",
    "\n",
    "smile_codes = raw_data.smiles.values\n",
    "ys = raw_data.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Data Generating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smile 코드로 되어있는 분자구조를 networkx의 형식에 맞게 변형한 후, torch geometric의 형태에 맞춰줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                     | 117/1128 [00:00<00:00, 1169.74it/s]E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"\\\", will be discarded\n",
      " 21%|████████████████                                                             | 235/1128 [00:00<00:00, 1175.62it/s]E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"\\\", will be discarded\n",
      " 31%|████████████████████████                                                     | 353/1128 [00:00<00:00, 1161.58it/s]E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      " 63%|████████████████████████████████████████████████▏                            | 706/1128 [00:00<00:00, 1173.39it/s]E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"\\\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      " 94%|███████████████████████████████████████████████████████████████████████▍    | 1061/1128 [00:00<00:00, 1177.25it/s]E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"\\\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"\\\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1128/1128 [00:00<00:00, 1172.29it/s]\n"
     ]
    }
   ],
   "source": [
    "chemical_indexs = {\"Br\" : 0, \n",
    "                  \"C\" : 1, \n",
    "                  \"Cl\" : 2, \n",
    "                  \"F\" : 3, \n",
    "                  \"I\" : 4, \n",
    "                  \"N\" : 5, \n",
    "                  \"O\" : 6, \n",
    "                  \"P\" : 7, \n",
    "                  \"S\" : 8}\n",
    "## There are 9 types of chemical indexs. Thus molecular feature should have 9-dimensional vectors.\n",
    "## There are [1.0, 1.5, 2.0, 3.0] types of bond. Thus edge attribute has 4-dimensional vectors, \n",
    "\n",
    "data = []\n",
    "for i in tqdm(range(smile_codes.shape[0])) : \n",
    "    tmp_y = ys[i]\n",
    "    formula = smile_codes[i]\n",
    "    mol = read_smiles(formula)\n",
    "    node_x = torch.zeros((len(nx.get_node_attributes(mol, name = \"element\")), \n",
    "                         9), dtype = torch.float)\n",
    "    edge_indexs = torch.tensor([[0], [0]], dtype = torch.long)\n",
    "    edge_attrs = torch.zeros((1,4), dtype = torch.long)\n",
    "    for x_ in range(node_x.shape[0]) : \n",
    "        item_ = nx.get_node_attributes(mol, name = \"element\")[x_]\n",
    "        node_x[x_, chemical_indexs[item_]] = 1\n",
    "        \n",
    "    ## Edge type 1.0 \n",
    "    index1 = torch.tensor([np.where(nx.to_numpy_matrix(mol, weight='order') == 1.0)[0],\n",
    "                           np.where(nx.to_numpy_matrix(mol, weight='order') == 1.0)[1]], dtype=torch.long)\n",
    "    if index1.shape[1] > 0 : \n",
    "        x1 = torch.zeros((index1.shape[1], 4), dtype = torch.float)\n",
    "        x1[:, 1] = 1\n",
    "        edge_indexs = torch.hstack([edge_indexs, index1])\n",
    "        edge_attrs = torch.vstack([edge_attrs, x1])\n",
    "        \n",
    "    ## Edge type 1.5\n",
    "    index1 = torch.tensor([np.where(nx.to_numpy_matrix(mol, weight='order') == 1.5)[0],\n",
    "                           np.where(nx.to_numpy_matrix(mol, weight='order') == 1.5)[1]], dtype=torch.long)\n",
    "    if index1.shape[1] > 0 : \n",
    "        x1 = torch.zeros((index1.shape[1], 4), dtype = torch.float)\n",
    "        x1[:, 1] = 1\n",
    "        edge_indexs = torch.hstack([edge_indexs, index1])\n",
    "        edge_attrs = torch.vstack([edge_attrs, x1])\n",
    "        \n",
    "    ## Edge type 2.0\n",
    "    index1 = torch.tensor([np.where(nx.to_numpy_matrix(mol, weight='order') == 2.0)[0],\n",
    "                           np.where(nx.to_numpy_matrix(mol, weight='order') == 2.0)[1]], dtype=torch.long)\n",
    "    if index1.shape[1] > 0 : \n",
    "        x1 = torch.zeros((index1.shape[1], 4), dtype = torch.float)\n",
    "        x1[:, 1] = 1\n",
    "        edge_indexs = torch.hstack([edge_indexs, index1])\n",
    "        edge_attrs = torch.vstack([edge_attrs, x1])\n",
    "        \n",
    "    ## Edge type 3.0\n",
    "    index1 = torch.tensor([np.where(nx.to_numpy_matrix(mol, weight='order') == 3.0)[0],\n",
    "                           np.where(nx.to_numpy_matrix(mol, weight='order') == 3.0)[1]], dtype=torch.long)\n",
    "    if index1.shape[1] > 0 : \n",
    "        x1 = torch.zeros((index1.shape[1], 4), dtype = torch.float)\n",
    "        x1[:, 1] = 1\n",
    "        edge_indexs = torch.hstack([edge_indexs, index1])\n",
    "        edge_attrs = torch.vstack([edge_attrs, x1])\n",
    "    \n",
    "    tmp_data = Data(x = node_x, \n",
    "                    edge_index = edge_indexs[:, 1:],\n",
    "                    edge_attr = edge_attrs[1:, :], \n",
    "                    y = torch.tensor([tmp_y], dtype = torch.float))\n",
    "    \n",
    "    data.append(tmp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_smile에서 지원하지 않는 일부 분자식은 호환되지 않은 것 같습니다.  \n",
    "데이터가 준비되었으니 train/test split을 수행하고 regression을 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_module = DataLoader(data[:700], batch_size = 5)\n",
    "test_data = data[700:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간중간 validation 데이터에 대해 성능평가를 진행하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(GNN_model, test_list) : \n",
    "    test_loss = 0\n",
    "    GNN_model.eval()\n",
    "    for part_d in test_data : \n",
    "        part_d = part_d.to(device)\n",
    "        y_ = GNN_model(part_d, training_with_batch = False)\n",
    "        loss_ = ((y_ - part_d.y)**2).to(\"cpu\").item()\n",
    "        test_loss += loss_\n",
    "    return test_loss/428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMP_Conv(dataset = data[0], \n",
    "                latent_dim = [16, 16, 16, 16],\n",
    "                device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMP_Conv(\n",
       "  (convs): ModuleList(\n",
       "    (0): NNConv(9, 16)\n",
       "    (1): NNConv(16, 16)\n",
       "    (2): NNConv(16, 16)\n",
       "    (3): NNConv(16, 16)\n",
       "  )\n",
       "  (edge_linear): ModuleList(\n",
       "    (0): Linear(in_features=4, out_features=144, bias=True)\n",
       "    (1): Linear(in_features=4, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=4, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=4, out_features=256, bias=True)\n",
       "  )\n",
       "  (last_linear): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch 0 / Training Loss 60.405122839553016 / Test Loss 14.06145891772064\n",
      "Current Epoch 10 / Training Loss 0.5672759013676217 / Test Loss 2.9552547900524138\n",
      "Current Epoch 20 / Training Loss 0.4924173589210425 / Test Loss 2.1455987956031257\n",
      "Current Epoch 30 / Training Loss 0.334241079049451 / Test Loss 1.4925726335443945\n",
      "Current Epoch 40 / Training Loss 0.2839846223167011 / Test Loss 1.4805337942837418\n",
      "Current Epoch 50 / Training Loss 0.19278290926877942 / Test Loss 1.2115028605720903\n",
      "Current Epoch 60 / Training Loss 0.18261436280395305 / Test Loss 1.234845954387699\n",
      "Current Epoch 70 / Training Loss 0.13969181974551506 / Test Loss 1.0407097304591695\n",
      "Current Epoch 80 / Training Loss 0.12937329895794392 / Test Loss 1.2184098831131582\n",
      "Current Epoch 90 / Training Loss 0.11010864088577883 / Test Loss 1.1203683731750513\n",
      "Current Epoch 100 / Training Loss 0.09735008151137403 / Test Loss 1.0527366639185012\n",
      "Current Epoch 110 / Training Loss 0.10218576756439039 / Test Loss 1.0559937198910716\n",
      "Current Epoch 120 / Training Loss 0.08268950319982 / Test Loss 0.9717593152068735\n",
      "Current Epoch 130 / Training Loss 0.08036511570215225 / Test Loss 0.9091397756567552\n",
      "Current Epoch 140 / Training Loss 0.07784529116802982 / Test Loss 0.8769456979504471\n",
      "Current Epoch 150 / Training Loss 0.07132769140015756 / Test Loss 0.8882599487645075\n",
      "Current Epoch 160 / Training Loss 0.06570102596655487 / Test Loss 0.9439223358658254\n",
      "Current Epoch 170 / Training Loss 0.06776542130059429 / Test Loss 0.931987609292704\n",
      "Current Epoch 180 / Training Loss 0.05576388460450939 / Test Loss 0.9325978145524636\n",
      "Current Epoch 190 / Training Loss 0.05537598740309477 / Test Loss 0.8992414272289717\n",
      "Current Epoch 200 / Training Loss 0.05847380744293332 / Test Loss 0.8963410003432677\n",
      "Current Epoch 210 / Training Loss 0.07047674516215921 / Test Loss 0.9163258738496178\n",
      "Current Epoch 220 / Training Loss 0.05440112559257874 / Test Loss 0.8594766782384434\n",
      "Current Epoch 230 / Training Loss 0.058829860745130906 / Test Loss 0.8834486708241813\n",
      "Current Epoch 240 / Training Loss 0.05696499111663018 / Test Loss 0.9245828841768363\n",
      "Current Epoch 250 / Training Loss 0.050132492299058605 / Test Loss 0.9264817113817116\n",
      "Current Epoch 260 / Training Loss 0.051044420636192495 / Test Loss 0.7757336752667223\n",
      "Current Epoch 270 / Training Loss 0.04953208211676351 / Test Loss 0.8064741139394619\n",
      "Current Epoch 280 / Training Loss 0.051382389826966184 / Test Loss 0.8088646733449084\n",
      "Current Epoch 290 / Training Loss 0.047099113302039246 / Test Loss 0.7505443158471311\n",
      "Current Epoch 300 / Training Loss 0.043759362364986114 / Test Loss 0.7736388888818672\n",
      "Current Epoch 310 / Training Loss 0.044571910483230434 / Test Loss 0.8540290827621717\n",
      "Current Epoch 320 / Training Loss 0.05440657600627414 / Test Loss 0.7904636325499367\n",
      "Current Epoch 330 / Training Loss 0.04100887781703412 / Test Loss 0.7839524366039776\n",
      "Current Epoch 340 / Training Loss 0.051943533958068916 / Test Loss 0.8245988454737302\n",
      "Current Epoch 350 / Training Loss 0.03982338802888989 / Test Loss 0.8446517339555986\n",
      "Current Epoch 360 / Training Loss 0.03737107075883874 / Test Loss 0.7557574439310331\n",
      "Current Epoch 370 / Training Loss 0.043876963265772374 / Test Loss 0.7637019279726778\n",
      "Current Epoch 380 / Training Loss 0.0387605693783345 / Test Loss 0.903955683064294\n",
      "Current Epoch 390 / Training Loss 0.03901959995539593 / Test Loss 0.7773173615652171\n",
      "Current Epoch 400 / Training Loss 0.03518986685600664 / Test Loss 0.78831869979953\n",
      "Current Epoch 410 / Training Loss 0.041482127435738224 / Test Loss 0.8373769047674078\n",
      "Current Epoch 420 / Training Loss 0.04069343245787812 / Test Loss 0.7756748040759064\n",
      "Current Epoch 430 / Training Loss 0.03745205874554813 / Test Loss 0.871474699985552\n",
      "Current Epoch 440 / Training Loss 0.035015270423942375 / Test Loss 0.8082079957339167\n",
      "Current Epoch 450 / Training Loss 0.03740739670981254 / Test Loss 0.8586656642891448\n",
      "Current Epoch 460 / Training Loss 0.034880201019612804 / Test Loss 0.7614954359599974\n",
      "Current Epoch 470 / Training Loss 0.040510638006962835 / Test Loss 0.7552472166804708\n",
      "Current Epoch 480 / Training Loss 0.04622218894639186 / Test Loss 0.8315950189882948\n",
      "Current Epoch 490 / Training Loss 0.03267837470630184 / Test Loss 0.8012415946072013\n"
     ]
    }
   ],
   "source": [
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for data in train_module : \n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data = data, \n",
    "                   training_with_batch = True)\n",
    "        loss = criterion(out.view(-1), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.to(\"cpu\").detach().item()\n",
    "    \n",
    "    if epoch % 10 == 0 : \n",
    "        print(\"Current Epoch {0} / Training Loss {1} / Test Loss {2}\".format(epoch, \n",
    "                                                                             epoch_loss/700, \n",
    "                                                                             evaluator(model, test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 Regression Task도 Classification과 유사하게 구현 가능합니다.  \n",
    "이후 다른 모델들도 이용하여 모델성능을 비교해보는 기회를 가져보겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunwoo_env",
   "language": "python",
   "name": "sunwoo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
